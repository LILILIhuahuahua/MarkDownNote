# 日志收集系统开发记录

## 日志收集系统架构设计

![image-20210616231122005](日志收集项目开发记录.assets/image-20210616231122005.png)

![image-20210616231133684](日志收集项目开发记录.assets/image-20210616231133684.png)



## kafka介绍

### kafka架构介绍

![image-20210616231310599](日志收集项目开发记录.assets/image-20210616231310599.png)

> kafka集群、Broker、Topic、Partition、Replication

![image-20210616231318256](日志收集项目开发记录.assets/image-20210616231318256.png)



### kafka工作流程

我们看上⾯的架构图中，producer就是⽣产者，是数据的⼊⼝。Producer在写⼊数据的时候会把数据 写⼊到leader中，不会直接将数据写⼊follower！那leader怎么找呢？写⼊的流程⼜是什么样的呢？我们看下图：

![image-20210616231528749](日志收集项目开发记录.assets/image-20210616231528749.png)



### 选择partition的原则

![image-20210616231836221](日志收集项目开发记录.assets/image-20210616231836221.png)



### ACK应答机制

![image-20210616231938694](日志收集项目开发记录.assets/image-20210616231938694.png)



### Topic和数据日志

`topic` 是同⼀类别的消息记录（record）的集合。在Kafka中，⼀个主题通常有多个订阅者。对于每个主题，Kafka集群维护了⼀个分区数据⽇志⽂件结构如下：

![image-20210616232444818](日志收集项目开发记录.assets/image-20210616232444818.png)

每个partition都是⼀个有序并且不可变的消息记录集合。当新的数据写⼊时，就被追加到partition的末 尾。在每个partition中，每条消息都会被分配⼀个顺序的唯⼀标识，这个标识被称为offset，即`偏移量`。注意，**Kafka只保证在同⼀个partition内部消息是有序的，在不同partition之间，并不能保证消息有序。**

 Kafka可以配置⼀个保留期限，⽤来标识⽇志会在Kafka集群内保留多⻓时间。Kafka集群会保留在保留 期限内所有被发布的消息，不管这些消息是否被消费过。⽐如保留期限设置为两天，那么数据被发布到 Kafka集群的两天以内，所有的这些数据都可以被消费。当超过两天，这些数据将会被清空，以便为后 续的数据腾出空间。由于Kafka会将数据进⾏持久化存储（即写⼊到硬盘上），所以保留的数据⼤⼩可 以设置为⼀个⽐较大的值。



### Partition结构

![image-20210616232703021](日志收集项目开发记录.assets/image-20210616232703021.png)



### 消费数据

多个消费者实例可以组成⼀个消费者组，并⽤⼀个标签来标识这个消费者组。⼀个消费者组中的不同消 费者实例可以运⾏在不同的进程甚⾄不同的服务器上。

 如果所有的消费者实例都在同⼀个消费者组中，那么消息记录会被很好的均衡的发送到每个消费者实例。

 如果所有的消费者实例都在不同的消费者组，那么每⼀条消息记录会被⼴播到每⼀个消费者实例。

![image-20210616232749080](日志收集项目开发记录.assets/image-20210616232749080.png)

举个例⼦，如上图所示⼀个两个节点的Kafka集群上拥有⼀个四个partition（P0-P3）的topic。有两个消费者组都在消费这个topic中的数据，消费者组A有两个消费者实例，消费者组B有四个消费者实例。

 从图中我们可以看到，**在同⼀个消费者组中，每个消费者实例可以消费多个分区，但是每个分区最多只能被消费者组中的⼀个实例消费**。也就是说，如果有⼀个4个分区的主题，那么消费者组中最多只能有4 个消费者实例去消费，多出来的都不会被分配到分区。其实这也很好理解，如果允许两个消费者实例同 时消费同⼀个分区，那么就⽆法记录这个分区被这个消费者组消费的offset了。如果在消费者组中动态的上线或下线消费者，那么Kafka集群会⾃动调整分区与消费者实例间的对应关系。



### kafka使用场景

上面介绍了Kafka的⼀些基本概念和原理，那么Kafka可以做什么呢？⽬前主流使⽤场景基本如下：

![image-20210616233029612](日志收集项目开发记录.assets/image-20210616233029612.png)

![image-20210616233037935](日志收集项目开发记录.assets/image-20210616233037935.png)



### kafka安装与运行

kafka本地安装目录：[E:\Kafka\kafka_2.8]()

```shell
//启动zookeeper
E:\Kafka\kafka_2.8\bin\windows>zookeeper-server-start.bat ..\..\config\zookeeper.properties

//启动kafka 需要先启动zookeeper
E:\Kafka\kafka_2.8\bin\windows>kafka-server-start.bat ..\..\config\server.properties
```



### 消费kafka中数据

> 使用kafka自带的kafka-console-consumer消费一下代码发生过去的消息

```
E:\Kafka\kafka_2.8\bin\windows>kafka-console-consumer.bat --bootstrap-server 127.0.0.1:9092 --topic shopping --from-beginning
```

![image-20210620155516256](日志收集项目开发记录.assets/image-20210620155516256.png)



## ZooKeeper

### ZooKeeper介绍

> Zookeeper用于做服务的注册、发现

ZooKeeper是⼀个分布式的，开放源码的分布式应⽤程序协调服务，是Google的Chubby⼀个开源的实 现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进⾏下⼀步合理操作。最 终，将简单易⽤的接⼝和性能⾼效、功能稳定的系统提供给⽤户。



### Zookeeper安装、运行

参考链接:https://www.runoob.com/w3cnote/zookeeper-setup.html

本地ZooKeeper安装目录：[E:\Software\CodeSoftware\Zookeeper\apache-zookeeper-3.7.0-bin]()





## sarama使用

> sarama为kafka客户端，用sarama向kafka发送消息
>
> #### 先启动zookeeper与kafka
>
> #### 参考“kafka安装与运行”

### 下载安装

```
go get github.com/Shopify/sarama
```

### kafka发送文件示例

> 设一个Topic为shopping，向其中发生数据

```go
package main

import (
	"fmt"
	"github.com/Shopify/sarama"
)

func main() {
	//1.生产者配置
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll          // 发送完数据需要leader和follow都确认
	config.Producer.Partitioner = sarama.NewRandomPartitioner // 新选出一个partition
	config.Producer.Return.Successes = true                   // 成功交付的消息将在success channel返回

	//2.连接kafka
	client, err := sarama.NewSyncProducer([]string{"127.0.0.1:9092"}, config)
	if err != nil {
		fmt.Println("producer closed, err:", err)
		return
	}
	defer client.Close()

	//3.封装消息
	msg :=&sarama.ProducerMessage{}
	msg.Topic = "shopping"
	msg.Value = sarama.StringEncoder("this is a test log")

	//4.发送消息
	pid, offset, err := client.SendMessage(msg)
	if err != nil {
		fmt.Println("send msg failed, err:", err)
		return
	}
	fmt.Printf("pid:%v offset:%v\n", pid, offset)

}
```



## tailf包

> tailf包用于读取文件内容

```go
package main

import (
	"fmt"
	"github.com/hpcloud/tail"
	"time"
)

//通过tail包，从文件中读取msg
func main() {
	fileName := `xx.log`
	//文件读取的权限
	config := tail.Config{
		ReOpen: true,
		Follow: true,
		Location: &tail.SeekInfo{Offset: 0, Whence: 2},
		MustExist: false,
		Poll: true,
	}

	//打开文件
	tails, err := tail.TailFile(fileName, config)
	if err != nil {
		fmt.Println("tail file failed, err:", err)
		return
	}
	var (
		msg *tail.Line
		ok bool
	)

	//读取文件的每一行
	for {
		msg, ok = <-tails.Lines
		if !ok {
			fmt.Printf("tail file close reopen, filename:%s\n",
				tails.Filename)
			//读取出错，等一秒在读
			time.Sleep(time.Second)
			continue
		}
		fmt.Println("msg:", msg.Text)
	}
}
```



## etcd介绍

### 介绍

etcd是使用Go语言开发的一个开源的、高可用的分布式key-value存储系统，==可以用于配置共享和服务的注册和发现==，类似项目有Zookeeper和consul

etcd具有以下特点

- 完全复制：集群中的每个节点都可以使用完整的存档
- 高可用性：Etcd可用于避免硬件的单点故障或网络问题（选择出另外的leader）
- 一致性：每次读取都会返回跨多主机的最新写入
- 简单：包括一个定义良好、面向用户的API（gRPC）
- 安全：实现了带有可选的客户端证书身份验证的自动化TLS
- 快速：每秒10000次写入的基准速度
- 可靠：使用 **Raft** 算法实现了强一致性，高可用的服务存储目录
  - Raft协议：选举、日志复制机制、异常处理（脑裂）、Zookeeper的zad协议的区别



### etcd应用场景

#### 服务发现

服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。

![image-20200910161600037](../../../../CodeStudyingResource/Go/文档/LearningNotes/Golang/Golang进阶/18_etcd介绍/images/image-20200910161600037.png)

### 配置中心

将一些配置信息放到etcd上进行集中管理。这类场景的使用方式通常是这样的：应用启动的时候，主动从etcd获取一次配置信息，同时，在etcd节点上注册一个Watcher并等待，以后每次配置有更新的时候，etcd都会实时通知订阅者，以此达到获取最新配置信息的目的。

### 分布式锁

因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致性的，所以很容易实现分布式锁。

锁服务有两种使用方式，一种是保持独占，二是控制时序。

- **保持独占即所有获取锁的用户最终只有一个可以得到**。etcd为此提供了一套实现分布式锁原子操作CAS（CompareAndSwap）的API。通过设置preExist值，可以保证在多个节点同时去创建某个目录时，只有一个成功，而创建成功的用户就可以认为是获得了锁。
- **控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。**etcd为此也提供了一套API（自动创建有序键），对一个目录建值时指定为POST动作，这样etcd会自动在目录下生成一个当前最大的键值。此时这些键的值就是客户端的时序，而这些键中的存储的值可以代表客户端的编号。

![image-20200910212441132](../../../../CodeStudyingResource/Go/文档/LearningNotes/Golang/Golang进阶/18_etcd介绍/images/image-20200910212441132.png)

上图就是三个同时来竞争锁，最后只有一个获取到了锁



### etcd架构

![image-20200910212915543](../../../../CodeStudyingResource/Go/文档/LearningNotes/Golang/Golang进阶/18_etcd介绍/images/image-20200910212915543.png)

从etcd的架构图中我们可以看到，etcd主要分为四个部分

- **HTTP Server**：用于处理用户发送的API请求以及其他etcd节点的同步与心跳信息请求
- **Store**：用于处理etcd支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是etcd对用户提供的大多数API功能的具体实现
- **Raft**：Raft强一致性算法的具体实现，是etcd的核心
- **WAL：Write Ahead Log（预写式日志）**，是etcd的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd就通过WAL进行持久化存储。WAL中，所有的数据提交前都会实现记录日志。**Snapshot是为了防止数据过多而进行的状态快照；Entry表示存储的具体日志内容。**



### etcd部署

> 部署文档：
>
> https://docs.qq.com/doc/DTndrQXdXYUxUU09O?opendocxfrom=admin



### etcd服务端

**运行:**

[E:\Software\CodeSoftware\Etcd\etcd-v3.5.0-windows-amd64\etcd.exe]()





### etcd客户端使用

```powershell
E:\Software\CodeSoftware\Etcd\etcd-v3.5.0-windows-amd64>etcdctl.exe --endpoints=http://127.0.0.1:2379 put s4 "123"
```



### etcd在go中使用

#### 导包

> go.mod中导入包
>
> **导包问题解决：**
>
> https://www.cnblogs.com/zanyouxin/p/13537307.html
>
> https://zh.codeprj.com/blog/bac2b71.html

```go
replace github.com/coreos/bbolt v1.3.4 => go.etcd.io/bbolt v1.3.4

replace google.golang.org/grpc => google.golang.org/grpc v1.26.0

require (
	go.etcd.io/etcd v3.3.13+incompatible //indirect
)
```



#### 连接etcd进行put、get

> **LogCollectionProject/ectdDemo/main**
>
> 使用context是进行连接的超时控制

```go
package main

import (
	"context"
	"fmt"
	"go.etcd.io/etcd/clientv3"
	"time"
)

//
func main() {
	//1.连接etcd
	cli, err := clientv3.New(clientv3.Config {
		Endpoints: []string{"127.0.0.1:2379"}, // etcd的节点，可以传入多个
		DialTimeout: 5*time.Second, // 连接超时时间
	})

	if err != nil {
		fmt.Printf("connect to etcd failed, err: %v \n", err)
		return
	}
	fmt.Println("connect to etcd success")

	// 延迟关闭
	defer cli.Close()

	// put操作  设置1秒超时
    //使用context是进行连接的超时控制
	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	_, err = cli.Put(ctx, "s4", "zhenbucuo")
	//cancel()
	if err != nil {
		fmt.Printf("put to etcd failed, err:%v \n", err)
		return
	}

	// get操作，设置1秒超时
    //使用context是进行连接的超时控制
	ctx, cancel = context.WithTimeout(context.Background(), time.Second)
	resp, err := cli.Get(ctx, "s4")
	cancel()
	if err != nil {
		fmt.Printf("get from etcd failed, err:%v \n", err)
		return
	}
	for _, msg:=range resp.Kvs{
		fmt.Printf("key:%s,value:%s",msg.Key,msg.Value)
	}

}

```



#### watch

> 使用watch可以监听etcd中某个key的变化，从而实现配置的热更新 （配置更新了，watch能监听到）

> **LogCollectionProject/etcdDemo/watchDemo/main.go**

```go
package main

import (
	"context"
	"fmt"
	"go.etcd.io/etcd/clientv3"
	"time"
)

//watch:监听etcd中某个key的变化
func main()  {
	cli, err := clientv3.New(clientv3.Config {
		Endpoints: []string{"127.0.0.1:2379"}, // etcd的节点，可以传入多个
		DialTimeout: 5*time.Second, // 连接超时时间
	})

	if err != nil {
		fmt.Printf("connect to etcd failed, err: %v \n", err)
		return
	}
	fmt.Println("connect to etcd success")
	defer cli.Close()

	// watch
	// 派一个哨兵，一直监视着 moxi 这个key的变化（新增，修改，删除），返回一个只读的chan
	watchChan := cli.Watch(context.Background(), "s4")

	// 从通道中尝试获取值（监视的信息）
	for wresp := range watchChan {
		for _, msg := range wresp.Events{
			fmt.Printf("Type:%v key:%s value:%s \n", msg.Type, msg.Kv.Key, msg.Kv.Value)
		}
	}
}
```



## gopsutil包

> 博客地址：https://www.liwenzhou.com/posts/Go/go_gopsutil/

### 介绍

`psutil`是一个**跨平台进程和系统监控**的Python库，而`gopsutil`是其Go语言版本的实现。本文介绍了它的基本使用。

Go语言部署简单、性能好的特点非常适合做一些诸如采集系统信息和监控的服务，本文介绍的[gopsutil](https://github.com/shirou/gopsutil)库是知名Python库：[psutil](https://github.com/giampaolo/psutil)的一个Go语言版本的实现。

### 安装

```bash
go get github.com/shirou/gopsutil
```

### 使用

#### CPU

**采集CPU相关信息。**

```go
import "github.com/shirou/gopsutil/cpu"

// cpu info
func getCpuInfo() {
	cpuInfos, err := cpu.Info()
	if err != nil {
		fmt.Printf("get cpu info failed, err:%v", err)
	}
	for _, ci := range cpuInfos {
		fmt.Println(ci)
	}
	// CPU使用率
	for {
		percent, _ := cpu.Percent(time.Second, false)
		fmt.Printf("cpu percent:%v\n", percent)
	}
}
```

**获取CPU负载信息：**

```go
import "github.com/shirou/gopsutil/load"

func getCpuLoad() {
	info, _ := load.Avg()
	fmt.Printf("%v\n", info)
}
```

#### Memory

```go
import "github.com/shirou/gopsutil/mem"

// mem info
func getMemInfo() {
	memInfo, _ := mem.VirtualMemory()
	fmt.Printf("mem info:%v\n", memInfo)
}
```

#### Host

```go
import "github.com/shirou/gopsutil/host"

// host info
func getHostInfo() {
	hInfo, _ := host.Info()
	fmt.Printf("host info:%v uptime:%v boottime:%v\n", hInfo, hInfo.Uptime, hInfo.BootTime)
}
```

#### Disk

```go
import "github.com/shirou/gopsutil/disk"

// disk info
func getDiskInfo() {
	parts, err := disk.Partitions(true)
	if err != nil {
		fmt.Printf("get Partitions failed, err:%v\n", err)
		return
	}
	for _, part := range parts {
		fmt.Printf("part:%v\n", part.String())
		diskInfo, _ := disk.Usage(part.Mountpoint)
		fmt.Printf("disk info:used:%v free:%v\n", diskInfo.UsedPercent, diskInfo.Free)
	}

	ioStat, _ := disk.IOCounters()
	for k, v := range ioStat {
		fmt.Printf("%v:%v\n", k, v)
	}
}
```

#### net IO

```go
import "github.com/shirou/gopsutil/net"

func getNetInfo() {
	info, _ := net.IOCounters(true)
	for index, v := range info {
		fmt.Printf("%v:%v send:%v recv:%v\n", index, v, v.BytesSent, v.BytesRecv)
	}
}
```



## grafana

展示数据的工具,监控数据可视化

* 搜索引擎找官网









# 日志收集系统开发

### logagent开发

#### logagent流程梳理

logagent流程:https://www.processon.com/view/link/5d3d05a4e4b0b3e4dcd547ec#map



#### ini配置文件解析

> 使用ini包解析配置文件，将配置文件与结构体双向转化
>
> ini包官方文档：https://ini.unknwon.io/docs/intro/getting_started



**配置信息**

> **LogCoectionProject/logagent/config下**

```ini
#kafka的配置信息
[kafka]
address = 127.0.0.1:9092
topic = shopping
chan_size = 10000
#需要收集的文件的配置信息
[collect]
#自己随便在路径下创建一个log文件
logfile_path = E:\Kafka\kafka_2.8\log\s5.log

#etcd的配置信息
[etcd]
address = 127.0.0.1:2379
collect_key = collect_log_conf
```



**解析配置文件**

> **LogCoectionProject/logagent/mian中**

```go
//0.ini配置文件解析(初始化连接kafka、读取文件准备)
var configObj = new(Config)
cfg , err := ini.Load("./config/config.ini")
if err != nil {
    logrus.Error("load config failed,err:%v", err)
    return
}

//0.1 将配置文件设置成结构体
err = cfg.MapTo(configObj)
if err != nil {
    logrus.Error("cfg.MapTo failed,err:%v", err)
    return
}
//fmt.Println(configObj)
```



#### struct数据结构

> 项目中用到的struct

> **LogCoectionProject/logagent/common/struct.go**

```go
package common

import "github.com/hpcloud/tail"

//整个项目的配置结构体
type Config struct {
	KafkaConfig      `ini:"kafka"`
	CollectionConfig `ini:"collect"`
	EtcdConfig       `ini:"etcd"`
}

type KafkaConfig struct {
	Address string `ini:"address"`
	Topic string `ini:"topic"`
	ChanSize int `ini:"chan_size"`
}

type CollectionConfig struct {
	LogFilepath string `ini:"logfile_path"`
}

type EtcdConfig struct {
	Address string `ini:"address"`
	CollectKey string `ini:"collect_key"`
}

//日志收集项的数据结构
type CollectEntry struct {
	Path string `json:"path"`//日志所在路径
	Topic string `json:"topic"`//日志的主题
}

```



#### main函数

```go
package main

import (
	"LogCollectionProject/logagent/common"
	"LogCollectionProject/logagent/etcd"
	"LogCollectionProject/logagent/kafka"
	"LogCollectionProject/logagent/tailfile"
	"fmt"
	"github.com/sirupsen/logrus" //日志打印包
	"gopkg.in/ini.v1"            //ini包用于映射配置文件成go中的结构体
)


//日志收集的客户端
//target:收集指定目录下的日志文件，发送到kafka中
func main() {
	//0.ini配置文件解析(初始化连接kafka、读取文件准备)
	var configObj = new(common.Config)
	cfg , err := ini.Load("./config/config.ini")
	if err != nil {
		logrus.Error("load config failed,err:%v", err)
		return
	}

	//0.1 将配置文件设置成结构体
	err = cfg.MapTo(configObj)
	if err != nil {
		logrus.Error("cfg.MapTo failed,err:%v", err)
		return
	}
	fmt.Printf("configObj:%s\n",configObj)

	//1. 初始化通过sarama连接kafka
	err = kafka.InitKafka([]string{configObj.KafkaConfig.Address},configObj.KafkaConfig.ChanSize)
	if err != nil {
		logrus.Error("kafka:InitKafka failed,err:%v", err)
		return
	}
	fmt.Println("inint kafka client success")

	//2.根据配置初始化etcd
	err = etcd.Init([]string{configObj.EtcdConfig.Address})
	if err != nil {
		logrus.Error("etcd:InitEtcd failed,err:%v", err)
		return
	}
	fmt.Println("inint etcd client success")

	//2.1从etcd中拉去需要收集的日志的配置项，方便tial去根据配置项读取日志内容
	allConfig:=etcd.GetCollectionConfig(configObj.EtcdConfig.CollectKey)
	fmt.Printf("allConfig:%s\n",allConfig)

	//3.根据配置中的日志路径初始化tail,并让tail到对应路径收集log文件内容
	err = tailfile.Init(allConfig)
	if err != nil {
		logrus.Error("tailfile:InitTailfile failed,err:%v", err)
		return
	}
	fmt.Println("inint tailfile client success")

	//4.把tial读取的日志内容通过sarama发送到kafka中
	//tailObj --> log --> kafkaClient -->kafka
	//tailfile.Init中完成了

	fmt.Println("run logagent success")
	for {

	}
}

```



#### kafka

##### 初始化kafka

> 使用sarama包连接kafka，获得一个kafka客户端，之后通过这个客户端向kafka服务器发送信息

> **LogCoectionProject/logagent/kafka/kafka.go中**

```go
package kafka

//kafka相关操作
import (
	"github.com/Shopify/sarama"
)

var(
	//kafka客户端对象
	Client sarama.SyncProducer
)

//初始化一个全局的kafka的客户端
func InitKafka(address []string) error{
	//1.生产者配置
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll          // 发送完数据需要leader和follow都确认
	config.Producer.Partitioner = sarama.NewRandomPartitioner // 新选出一个partition
	config.Producer.Return.Successes = true                   // 成功交付的消息将在success channel返回
                                                                                                                                 
	//2.连接kafka
	Client, err := sarama.NewSyncProducer(address, config)
	if err != nil {
		return err
	}
	defer Client.Close()

	//起一个goroutine专门用于发送msg到kafka
	go SendMsgToKafka()
	return nil
}
```



##### kafka增加SendMsgToKafka功能

> 从MsgChan中读取msg，发送给kafka

> **LogCoectionProject/logagent/kafka/kafka.go中**

```go
//从MsgChan中读取msg，发送给kafka
func SendMsgToKafka(){
	for {
		//从MsgChan中读取msg
		select {
		case msg := <-MsgChan:
			fmt.Println(msg)
			pid, offset, err := client.SendMessage(msg)
			if err != nil {
				logrus.Error("kafka:SendMsgToKafka failed, err:", err)
				return
			}
			logrus.Info("send msg to kafka success,pid:%v,offset:%v",pid,offset)
		}
	}
}
```





#### tailfile

##### 初始化tail

> 使用tail读取指定目录下的log文件的内容，方便后续将读取的内容发送到kafka中

> **LogCoectionProject/logagent/tailfile/tailfile.go中**

```go
package tailfile

import (
	"LogCollectionProject/logagent/common"
	"LogCollectionProject/logagent/kafka"
	"context"
	"fmt"
	"github.com/hpcloud/tail"
	"github.com/sirupsen/logrus"
	"strings"
	"time"
)

//tailTask结构体: 每个tailTask对应一个tailObj，通过tailObj读取对应path下文件的内容
type tailTask struct {
	path string
	topic string
	tailObj *tail.Tail
	ctx context.Context
	cancel context.CancelFunc
}

var(
	Config  tail.Config
)


func Init(allConfig []common.CollectEntry)(err error){
	//allConfig中存有若干个日志的手机项
	//针对每一个日志收集项创建一个对象的tailObj

	//1.初始化一个tailTask的管理者
	tailTaskManager := InitTailTaskManager(allConfig)

	//2.设置tail读取文件的权限
	Config = tail.Config{
		ReOpen: true,
		Follow: true,
		Location: &tail.SeekInfo{Offset: 0, Whence: 2},
		MustExist: false,
		Poll: true,

	}

	//2.1针对每一个日志收集项创建一个对象的tailObj
	for _,colEntry:= range allConfig{
		//根据每个收集日志项，创建并启动一个tail
		Run(tailTaskManager,colEntry)
	}


	//3.TTaskManager不断监听新的配置 (从SendNewConf不断取新的config)
	go TTaskManager.watch()

	return
}

//创建并运行一个tail对象
func Run(tailTaskManager tailTaskManager,colEntry common.CollectEntry)(err error){
	//打开文件
	TailObj, err := tail.TailFile(colEntry.Path, Config)
	if err != nil {
		logrus.Errorf("tailfile.Init: create tailObj failed,path:%s\n",colEntry.Path)
		return err
	}
	ctx,cancel :=context.WithCancel(context.Background())
	ttask :=tailTask{
		path:colEntry.Path,
		topic: colEntry.Topic,
		tailObj: TailObj,
		ctx: ctx,
		cancel: cancel,
	}
	//创建一个ttask就交给tailTaskManager管理,方便后续管理
	tailTaskManager.tailTaskMap[ttask.path] = &ttask

	//创建任务成功，直接让tailObj去收集日记
	fmt.Printf("creat a tailObj,  path:%s\n",ttask.path)
	go ttask.CollectLogMsg()
	return
}
```



##### tialfile.go增加CollectLogMsg功能

> 通过tialObj读取日记文件，封装成kafka中msg类型，丢到kafka的channel中
>
> CollectLogMsg添加Context.Done()的通道的监听，便于关闭启动CollectLogMsg的协程

> **LogCoectionProject/logagent/tailfile/tailfile.go中**

```go
//通过tialObj读取日记文件，封装成kafka中msg类型，丢到kafka的channel中
func (ttask *tailTask)CollectLogMsg(){
	var (
		lineMsg *tail.Line
		ok bool
	)
	//读取文件的每一行,封装成kafka中msg类型，丢到kafka的channel中

	for {
		//通过context优雅的关闭gorutine
		select {
		case <-ttask.ctx.Done():
			fmt.Printf("关闭一个ttask.CollectLogMsg的gorutine , path：%s\n",ttask.path)
			return
		case lineMsg, ok = <-ttask.tailObj.Lines:
			if !ok {
				logrus.Warnf("tail file fial open file, filename:%s\n",
					ttask.tailObj.Filename)
				//读取出错，等一秒在读
				time.Sleep(time.Second)
				continue
			}
			if len(strings.Trim(lineMsg.Text,"\r"))==0{
				continue
			}
			//2.读取到的一行msg封装成kafka中msg类型，丢到kafka的channel中
			fmt.Printf("len = %v  ,readLog-lineMsg:%v\n",len(lineMsg.Text),lineMsg.Text)
			kafkaMsg := kafka.ToKafkaMsg("shopping", lineMsg.Text)
			kafka.MsgChan <- kafkaMsg
		}

	}
}


```



##### 增加tailManager对tail的管理

> tailManager监听collectEntryChan有无新的配置
>
> tailManager负责优雅的关闭tail.collectMsg的gorutine

> **LogCoectionProject/logagent/tailfile/tailfile_manager.go中**

```go
package tailfile

import (
	"LogCollectionProject/logagent/common"
	"fmt"
)

/**
 * @author xhli
 * @date 2021/6/24 15:03
 * @version 1.0
 * @description: tailtask管理者
 */
type tailTaskManager struct {
	tailTaskMap map[string]*tailTask            //管理全局tailTask的map
	collectEntryList []common.CollectEntry      //初始化时，初始配置
	collectEntryChan chan []common.CollectEntry //等待新配置的通道
}

var (
	//全局的tailtask管理对象
	TTaskManager tailTaskManager
)

func InitTailTaskManager(allConf []common.CollectEntry) tailTaskManager{
	TTaskManager = tailTaskManager{
		tailTaskMap: make(map[string]*tailTask,20),
		collectEntryList:allConf,
		collectEntryChan: make(chan []common.CollectEntry),
	}
	return TTaskManager
}

//TTaskManager不断监听新的配置 (从SendNewConf不断取新的config)
func(ttManager tailTaskManager) watch(){
	//for 死循环，监听ttManager.collectEntryChan中有无新的配置
	for {
		//1、取出新的配置数组
		newConfs :=<-ttManager.collectEntryChan
		fmt.Println("get newConfs from ttManager.collectEntryChan,newConfs:",newConfs)
		//2、判断是否是新的配置
		for _,newConf :=range newConfs {
			if ttManager.isConfExist(newConf) {
				//旧的配置
				continue
			}
			//新的配置
			//根据每个收集日志项，创建并启动一个tail
			Run(ttManager,newConf)
		}

		//将newConf中不存在，而tailTakMap中存在的收集项对应的tailObj关掉
		for key,ttask :=range ttManager.tailTaskMap {
			var found bool
			for _,conf :=range newConfs{
				if key == conf.Path {
					found=true
					break
				}
			}
			//需要关闭这个任务
			if found==false{
				//ttaskManager不再管理这个任务
				delete(ttManager.tailTaskMap,key)
				//关闭这个任务的gorutine （tailfile.collectMsg的gorutine）
				ttask.cancel()
			}
		}
	}
}

func(ttManager tailTaskManager) isConfExist(conf common.CollectEntry) bool{
	_,ok :=ttManager.tailTaskMap[conf.Path]
	return ok
}

```



#### etcd

##### 连接etcd

> 使用etcd，方便从etcd中获取多个日志文件的配置项，或者通过watch监听配置项的变化

> **LogCoectionProject/logagent/etcd/etcd.go中**

```go
package etcd

import (
	"LogCollectionProject/logagent/common"
	"context"
	"encoding/json"
	"fmt"
	"github.com/sirupsen/logrus"
	"go.etcd.io/etcd/clientv3"
	"time"
)

//etcd相关操作
var(
	//etcd的客户端对象
	Client *clientv3.Client
)

//初始化etcd连接
func Init(address []string)(err error){
	//1.连接etcd
	Client, err = clientv3.New(clientv3.Config {
		Endpoints: address, // etcd的节点，可以传入多个
		DialTimeout: 5*time.Second, // 连接超时时间
	})

	if err != nil {
		fmt.Printf("connect to etcd failed, err: %v \n", err)
		return err
	}
	fmt.Println("etcd:connect to etcd success")

	return
}
```



##### 拉取配置项函数

> 通过etcd拉取日志收集的配置项的函数
>
> 假定:在ectd中存有json格式的日志收集的配置项（路径）

> **LogCoectionProject/logagent/etcd/etcd.go中**

```go
/**
	通过etcd拉取日志收集的配置项的函数
	假定:在ectd中存有json格式的日志收集的配置项（路径）
 **/
func GetCollectionConfig(key string)(collectEntryList []common.CollectEntry){
	//get操作，设置1秒超时
	//使用context是为了设置连接的超时时间
	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()
	//拉取json格式的日志收集的配置项（路径）
	resp, err := Client.Get(ctx, key)
	if err != nil {
		fmt.Printf("get conf from etcd failed, err:%v \n", err)
		return
	}

	if len(resp.Kvs) == 0 {
		logrus.Warnf("get len=0 conf from etcd by key:%s",key)
		return
	}
	//解析json映射成collectEntry对象
	result :=resp.Kvs[0]
	fmt.Printf("result.Value:%s\n",result.Value)
	err = json.Unmarshal(result.Value,&collectEntryList)
	if err != nil {
		fmt.Printf("etcd.GetCollectionConfig:json.Unmarshal failed, err:%v \n", err)
		return
	}
	return collectEntryList
}
```



##### watch监听

> 程序启动之后，获取最新的配置之后，就通过watch监听etxd中`key="collect_log_conf"`配置的变化

> **LogCoectionProject/logagent/etcd/etcd.go中**

```go
//通过watch监听etxd中`key="collect_log_conf"`配置的变化
func WatchConfig(collectKey string){
	watchChan := Client.Watch(context.Background(),collectKey)

	// 从通道中尝试获取值（监视的信息）
	var newCollectEntryList []common.CollectEntry
	for wresp := range watchChan {
		for _, watchMsg := range wresp.Events{
			fmt.Printf("etcd.WatchConfig: etch config chang-->Type:%v key:%s value:%s \n", watchMsg.Type, watchMsg.Kv.Key, watchMsg.Kv.Value)
			//解析新的配置信息
			err := json.Unmarshal(watchMsg.Kv.Value,&newCollectEntryList)
			if err != nil {
				fmt.Printf("etcd.WatchConfig:json.Unmarshal failed, err:%v \n", err)
				continue
			}
			//告诉tailfile模块，需要收集的日志Config改变了
			tailfile.SendNewConf(newCollectEntryList)
			fmt.Printf("etcd.WatchConfig: newCollectEntryList:%s \n",newCollectEntryList)


		}
	}
}
```

